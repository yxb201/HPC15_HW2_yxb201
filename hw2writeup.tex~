\documentclass[12pt]{article}

%% FONTS
%% To get the default sans serif font in latex, uncomment following line:
 \renewcommand*\familydefault{\sfdefault}
%%
%% to get Arial font as the sans serif font, uncomment following line:
%% \renewcommand{\sfdefault}{phv} % phv is the Arial font
%%
%% to get Helvetica font as the sans serif font, uncomment following line:
% \usepackage{helvet}
\usepackage[small,bf,up]{caption}
\renewcommand{\captionfont}{\footnotesize}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{graphics,epsfig,graphicx,float,subfigure,color}
\usepackage{amsmath,amssymb,amsbsy,amsfonts,amsthm}
\usepackage{url}
\usepackage{boxedminipage}
\usepackage[sf,bf,tiny]{titlesec}
 \usepackage[plainpages=false, colorlinks=true,
   citecolor=blue, filecolor=blue, linkcolor=blue,
   urlcolor=blue]{hyperref}
\usepackage{enumitem}

\newcommand{\todo}[1]{\textcolor{red}{#1}}
% see documentation for titlesec package
% \titleformat{\section}{\large \sffamily \bfseries}
\titlelabel{\thetitle.\,\,\,}


\newcommand{\bs}{\boldsymbol}
\newcommand{\alert}[1]{\textcolor{red}{#1}}
\setlength{\emergencystretch}{20pt}

\begin{document}

\begin{center}

\large \textbf{%%
High Performance Computing \\ Assignment \#2 \\ Yuan-Xun Bao \\ yxb201@nyu.edu \quad N13392943}
\end{center}

% ****************************
\section{Parallel Sample Sort}

\subsection{Strong Scalability}
To test the strong scalability of \verb|ssort|, we fix the total length of the array to be $NP = 2^{30} \approx 10^{10}$.
With this input size, \verb|ssort| scales up to 128 processors. 

\begin{center}
  \begin{tabular}{ | c | c | }
    \hline
    \# of procs & avg timing per node  \\ \hline
    16  & 18.3766s  \\ \hline
    32  & 9.2225s \\ \hline
    64  & 4.6401s  \\ \hline
    128 & 2.7381s \\ \hline
    256 & 2.2658s \\ \hline
    512 & 2.7244s \\
    \hline
  \end{tabular}
\end{center}

\subsection{Weak Scalability}

To test the weak scalability of \verb|ssort|, we fix the array length on each processor to be $N = 10^8$.
As the number of processors doubles, the computational time per node only increases slightly due to more inter-processor communications.

\begin{center}
  \begin{tabular}{ | c | c | }
    \hline
    \# of procs & avg timing per node  \\ \hline
    16  & 27.9859s  \\ \hline
    32  & 29.2918s \\ \hline
    64  & 30.2139s  \\ \hline
    128 & 30.9417s \\ \hline
    256 & 31.5131s \\ \hline
    512 & 32.7298s \\
    \hline
  \end{tabular}
\end{center}

\section{Final Project: Parallel NUFFT}
The Fourier transform of a collection of sample data $\{ \mathbf{x}_j \}_{j=1}^M$ in $d$-dimension concerns a sum of the following form:
\begin{equation}
 F(\mathbf{k}) = \sum_{j=0}^{M-1} f_j e^{-i \mathbf{k} \cdot \mathbf{x}_j}, \quad \text{for } -\frac{N}{2} \leq \mathbf{k} \leq \frac{N}{2} - 1 . \label{type1_nufft}
\end{equation}
When the data $\{\mathbf{x}_j\}_{j=1}^M$ are equispaced and $M = O(N^d)$, the sum can be evaluated uing the FFT in $O(N^d\log N)$ operations rather than $O(N^{2d})$ directly. However, in many applications areas, from medical imaging to signal processing, the sampling data are typically non-uniformly distributed. The challenge here is to extend the FFT and evaluate  \eqref{type1_nufft} in $O(N^d\log N)$ operations.

\subsection{The NUFFT Algorithm}
For simplicity, let us consider the one-dimensional case first. Suppose $x_j \in [0,2\pi]$, the type-1 NUFFT (Non-uniform FFT) is defined as 
\begin{equation}
 F(k) = \sum_{j=0}^{N-1} f_j e^{-i k x_j}, \quad \text{for } -\frac{N}{2} \leq k \leq \frac{N}{2} - 1. \label{type1_nufft2}
\end{equation}
The idea of the NUFFT is based on several important observations:
\begin{enumerate}
 \item The sum \eqref{type1_nufft2} is closesly related to the exact Fourier coefficients of the  function defined on $[0, 2\pi]$ (with periodic extensions) 
 \begin{equation}
  f(x) = \sum_{j=0}^{N-1} f_j \delta(x-x_j).
 \end{equation}
 \item Since $f(x)$ has spikes at $x_j$ and is not well-resolved by a uniform mesh, we convolve it with a perodic Gaussian kernel on $[0,2\pi]$ defined by
 \begin{equation}
  g_{\tau} = \sum_{l = -\infty}^{\infty} e^{-(x-2l\pi)^2/4\tau},
 \end{equation}
 and get 
 \begin{equation}
  f_{\tau} = (f * g_{\tau})(x) = \int_{0}^{2\pi} f(y) g_{\tau}(x-y) dy. \label{ftau}
 \end{equation}
 \item The Fourier coefficients of $f_{\tau}$, namely, 
 \begin{equation}
  F_{\tau}(k) = \frac{1}{2\pi} \int_0^{2\pi} f_{\tau}(x) e^{-ikx}dx,
 \end{equation}
 can be efficiently computed with high accuracy by the FFT on an oversampled grid
 \begin{equation}
  F_{\tau}(k) \approx \frac{1}{M_r} \sum_{m=0}^{M_r-1} f_{\tau}(2\pi/M_r) e^{-ik2\pi m / M_r},
 \end{equation}
 where 
 \begin{equation}
  f_{\tau}(2\pi m / M_r) = \sum_{j=0}^{N-1} f_j g_{\tau}(2\pi m / M_r - x_j).
 \end{equation}

 \item Finally, once the values $F_{\tau}(k)$ are known, we can compute $F(k)$ by deconvolution
 \begin{equation}
  F(k) = \sqrt{\frac{\pi}{\tau}} e^{k^2 \tau} F_{\tau}(k).
 \end{equation}

\end{enumerate}

The dominant task in the NUFFT is the calcuation of $f_{\tau}(2\pi m/M_r)$. Following the standard convention, we refer to this process as \textit{gridding}. Instead of focusing on the target points $2\pi m / M_r$, we change our view point to the source points $x_j$. Each source point $x_j$ spreads the computed weights to a finite collection of nearby target points $2\pi m/ M_r$. As for the target points, we simply sum up the received weights from all relevant sources. There are a few details that need to be addressed here. Firstly, as a rule of thumb, the spreading radius is set to be 12 grid points in each direction for 6 digits of accurcay and 24 grid points for 12 digits of accuracy. Secondly, the selection of $\tau$, which controls how wide-spread the Gaussian kernel is, is set to be $\tau = 6/N^2$ for 6-digits of accuracy and $\tau = 12/ N^2$ for 12 digits of accuracy. Thirdly, the size of the oversampled grid is $M_r  = 2N$. 
  
\subsection{Ideas for Parallelizing the NUFFT}
The gridding process is inherently local and is ideal for parallelization. Firstly, we divide our domain $[0,2\pi]$ into equispaced cells. Each cell contains a number of target points $2\pi m /M_r$ and source points $x_j$. Each processor is entirely responsible for the compution within a cell. For each cell, we first carry out the gridding process and send the computed weights to the relevant target points. If a target point is outside its cell, an MPI inter-processor communcation should be estabilished and send the weights to the coressponding target. Once all targets have received the weights, the next step is to use a version the parallel FFT to compute $F_{\tau}(k)$. Finally, $F(k)$ can be computed by deconvolution locally (This project is an individual one)ã€‚

\end{document}
